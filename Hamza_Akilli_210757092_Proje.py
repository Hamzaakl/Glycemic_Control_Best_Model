# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_Esl5sz4CGaQCT8KJ6XLp-ehGLaiHbcu
"""

"""
Hamza Akıllı
210757092
Yapay Zekaya Giriş
data = https://data.mendeley.com/datasets/rr4rzzrjfc/2
5 makine öğrenmesi 3 derin öğrenme
    "Lojistik Regresyon
    "Karar Ağacı
    "Random Forest
    "SVM"
    "Gradient Boosting
    "tabnet
    "mlp
    "attention


"""

import pandas as pd


dosya_yolu = '/content/data_export_icin.csv'
veri = pd.read_csv(dosya_yolu)

# Kategorik ve sayısal değişkenlerin ayrıştırılması
kategorik_degiskenler = [sutun for sutun in veri.columns if veri[sutun].nunique() <= 10]  # Az sayıda benzersiz değere sahip değişkenler
sayisal_degiskenler = [sutun for sutun in veri.columns if sutun not in kategorik_degiskenler]  l

# Eksik veri analizi
eksik_veriler = veri.isnull().sum()
eksik_veri_yuzdesi = (eksik_veriler / len(veri)) * 100

# Sayısal değişkenlerin istatistikleri
sayisal_ozet = veri[sayisal_degiskenler].describe()

# Kategorik değişkenlerin  istatistikleri
kategorik_ozet = veri[kategorik_degiskenler].describe()

# Eksik veri ve veri türleri özeti
print("Eksik Veri Sayısı ve Yüzdesi:")
print(pd.DataFrame({
    "Eksik Değerler": eksik_veriler,
    "Eksik (%)": eksik_veri_yuzdesi
}))

print("\nKategorik Değişkenler:")
print(kategorik_degiskenler)

print("\nSayısal Değişkenler:")
print(sayisal_degiskenler)

print("\nSayısal Değişkenlerin Özeti:")
print(sayisal_ozet)

print("\nKategorik Değişkenlerin Özeti:")
print(kategorik_ozet)

veri.head()

veri.info()

veri.shape

import matplotlib.pyplot as plt
import seaborn as sns

# değerlerin görselleştirilmesi
def boxplot_ciz(data, columns):
    for column in columns:
        plt.figure(figsize=(10, 5))
        sns.boxplot(x=data[column])
        plt.title(f"{column} için Boxplot")
        plt.xlabel(column)
        plt.show()

# IQR yöntemiyle uç değer analizi
def iqr_outlier_detection(data, columns):
    outliers = {}
    for column in columns:
        Q1 = data[column].quantile(0.25)
        Q3 = data[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        outliers[column] = data[(data[column] < lower_bound) | (data[column] > upper_bound)]
    return outliers

# Sayısal değişkenler için boxplot çizimi
boxplot_ciz(veri, sayisal_degiskenler[:10])  # İlk 10 sayısal değişken için görselleştirme

# IQR yöntemiyle uç değerlerin analizi
uc_degerler = iqr_outlier_detection(veri, sayisal_degiskenler)

# Uç değer analizi sonuçlarını yazdırma
for sutun, outlier_data in uc_degerler.items():
    print(f"{sutun} sütununda {len(outlier_data)} uç değer bulundu.")

import matplotlib.pyplot as plt

# Kategorik değişkenler için görselleştirme
def kategorik_gorsellestirme(data, columns):
    for column in columns:
        plt.figure(figsize=(10, 5))
        data[column].value_counts().plot(kind='bar')
        plt.title(f"{column} için Frekans Grafiği")
        plt.xlabel(column)
        plt.ylabel("Frekans")
        plt.xticks(rotation=45)
        plt.show()

# Kategorik değişkenler için görselleştirme işlemi
if kategorik_degiskenler:
    kategorik_gorsellestirme(veri, kategorik_degiskenler)
else:
    print("Kategorik değişken bulunamadı.")

# Sayısal ve kategorik veriler için uç değer analizi
def tum_veriler_icin_uc_deger_analizi(data, numerical_columns, categorical_columns):
    uc_deger_sonuclari = {}

    # Sayısal veriler için IQR yöntemi
    for column in numerical_columns:
        Q1 = data[column].quantile(0.25)
        Q3 = data[column].quantile(0.75)
        IQR = Q3 - Q1
        alt_sinir = Q1 - 1.5 * IQR
        ust_sinir = Q3 + 1.5 * IQR
        uc_deger_sonuclari[column] = data[(data[column] < alt_sinir) | (data[column] > ust_sinir)]

    # Kategorik veriler için anormal kategorilerin tespiti
    for column in categorical_columns:
        frekanslar = data[column].value_counts()
        nadir_degerler = frekanslar[frekanslar < 0.05 * len(data)]  # Toplam veri sayısının %5'inden az olan değerler
        uc_deger_sonuclari[column] = data[data[column].isin(nadir_degerler.index)]

    return uc_deger_sonuclari


# Uç değer analizi çalıştırma
tum_uc_degerler = tum_veriler_icin_uc_deger_analizi(veri, sayisal_degiskenler, kategorik_degiskenler)

# Analiz sonuçlarını yazdırma
for sutun, uc_degerler in tum_uc_degerler.items():
    print(f"{sutun} sütununda {len(uc_degerler)} uç değer/anormal değer bulundu.")

# Sayısal veriler için uç değerleri  silen fonksiyon
def uc_deger_sil(data, numerical_columns):
    for column in numerical_columns:
        Q1 = data[column].quantile(0.25)
        Q3 = data[column].quantile(0.75)
        IQR = Q3 - Q1
        alt_sinir = Q1 - 1.5 * IQR
        ust_sinir = Q3 + 1.5 * IQR

        # Aykırı değer içeren satırları filtrele
        data = data[(data[column] >= alt_sinir) & (data[column] <= ust_sinir)]
    return data

# Tüm veriler için uç değer analizi ve silme
def tum_veriler_icin_uc_deger_analizi_ve_sil(data, numerical_columns, categorical_columns):
    # Sayısal veriler için uç değer analizi ve satır silme
    data_cleaned = uc_deger_sil(data, numerical_columns)

    # Kategorik verilerde nadir değerleri tespit etme
    for column in categorical_columns:
        counts = data[column].value_counts(normalize=True)
        rare_categories = counts[counts < 0.01].index  # %1'den az görülen kategoriler
        data_cleaned = data_cleaned[~data_cleaned[column].isin(rare_categories)]

    return data_cleaned

# Aykırı değerleri silme işlemi
veri_cleaned = tum_veriler_icin_uc_deger_analizi_ve_sil(veri, sayisal_degiskenler, kategorik_degiskenler)

# Temizlenmiş veri setinin boyutlarını yazdırma
print(f"Orijinal veri seti boyutu: {veri.shape}")
print(f"Temizlenmiş veri seti boyutu: {veri_cleaned.shape}")

veri_cleaned.info()

#  Korelasyon Analizi hedef değişken
korelasyon = veri_cleaned[sayisal_degiskenler + ["Glycemic_control"]].corr()
print("Korelasyon Analizi:")
print(korelasyon["Glycemic_control"].sort_values(ascending=False))

print("\nScatter Plotlar:")
for column in sayisal_degiskenler:
    plt.figure(figsize=(10, 5))
    sns.scatterplot(x=veri_cleaned[column], y=veri_cleaned["Glycemic_control"])
    plt.title(f"{column} ve Glycemic_control Scatter Plot")
    plt.xlabel(column)
    plt.ylabel("Glycemic_control")
    plt.show()

# Regresyon Analizi
import statsmodels.api as sm

print("\nRegresyon Analizleri:")
for column in sayisal_degiskenler:
    X = veri_cleaned[[column]]
    y = veri_cleaned["Glycemic_control"]
    X = sm.add_constant(X)
    model = sm.OLS(y, X).fit()
    print(f"{column} için Regresyon Özeti:")
    print(model.summary())
    print("\n")

from sklearn.ensemble import RandomForestClassifier

X = veri_cleaned[sayisal_degiskenler]
y = veri_cleaned["Glycemic_control"]
model = RandomForestClassifier(random_state=42)
model.fit(X, y)

importance = pd.DataFrame({
    "Feature": X.columns,
    "Importance": model.feature_importances_
}).sort_values(by="Importance", ascending=False)

print(importance)

from sklearn.feature_selection import mutual_info_classif

X = veri_cleaned[sayisal_degiskenler]
y = veri_cleaned["Glycemic_control"]
mutual_info = mutual_info_classif(X, y)

importance = pd.DataFrame({
    "Feature": X.columns,
    "Mutual Information": mutual_info
}).sort_values(by="Mutual Information", ascending=False)

print(importance)

kaldirilacak_degiskenler = [
    "id",
    "akarboz", "dapagliflozin", "eksenatid", "gliklazid", "glimepirid",
    "glipizid", "insulin_aspart", "insulin_detemir", "insulin_glarjin",
    "insulin_glusilin", "insulin_lispro", "insulin_nph", "insulin_reguler",
    "linagliptin", "metformin_hcl", "nateglinid", "pioglitazon_hcl",
    "repaglinide", "saksagliptin", "sitagliptin", "vildagliptin"
]

# seçilen değişkenleri çıkarıyoruz
veri_temizlenmis = veri_cleaned.drop(columns=kaldirilacak_degiskenler, errors="ignore")

# Temizlenmiş veri seti
print("Kaldırılan Değişkenler:", kaldirilacak_degiskenler)
print("Yeni Veri Seti Boyutları:", veri_temizlenmis.shape)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from scipy.stats import chi2_contingency



# Kategorik değişkenlerin hedef değişkenle frekans dağılımı
for column in kategorik_degiskenler:
    plt.figure(figsize=(10, 5))
    sns.countplot(x=veri_cleaned[column], hue=veri["Glycemic_control"])
    plt.title(f"{column} ve Glycemic_control Frekans Dağılımı")
    plt.xlabel(column)
    plt.ylabel("Frekans")
    plt.legend(title="Glycemic_control", loc='upper right')
    plt.xticks(rotation=45)
    plt.show()

# Ki-kare testi ile bağımsızlık analizi
print("Ki-kare Testi Sonuçları:")
for column in kategorik_degiskenler:
    contingency_table = pd.crosstab(veri_cleaned[column], veri["Glycemic_control"])
    chi2, p, dof, expected = chi2_contingency(contingency_table)
    print(f"{column}:")
    print(f"  Ki-kare Değeri = {chi2:.2f}, p-değeri = {p:.5f}")
    if p < 0.05:
        print("  ==> Hedef değişken ile kategorik değişken arasında anlamlı bir ilişki vardır.")
    else:
        print("  ==> Hedef değişken ile kategorik değişken arasında anlamlı bir ilişki yoktur.")
    print()

# Kategorik değişkenlerin özet bilgileri
kategorik_ozet = {}
for column in kategorik_degiskenler:
    kategorik_ozet[column] = {
        "Unique Classes": veri_cleaned[column].nunique(),

        "Missing Values": veri_cleaned[column].isnull().sum()
    }

# Kategorik veriler için genel özet
kategorik_ozet_df = pd.DataFrame(kategorik_ozet).T
print("Kategorik Değişkenlerin Genel Özeti:")
print(kategorik_ozet_df)

# Nadir sınıfların Frekansı %1'in altında olan sınıflar
nadir_siniflar = {}
for column in kategorik_degiskenler:
    frekanslar = veri_cleaned[column].value_counts(normalize=True)
    nadir_siniflar[column] = frekanslar[frekanslar < 0.01].index.tolist()

print("\nNadir Sınıflar (%1'in altında):")
for column, classes in nadir_siniflar.items():
    print(f"{column}: {classes}")

# Kategorik değişkenler için Ki-kare testi
chi_square_results = {}
for column in kategorik_degiskenler:
    contingency_table = pd.crosstab(veri_cleaned[column], veri["Glycemic_control"])
    chi2, p, dof, expected = chi2_contingency(contingency_table)
    chi_square_results[column] = {"Chi2": chi2, "p-value": p}

# Ki-kare test sonuçları
chi_square_df = pd.DataFrame(chi_square_results).T
chi_square_df["Significant"] = chi_square_df["p-value"] < 0.05

print("\nKi-Kare Testi Sonuçları:")
print(chi_square_df)

# Hem nadir sınıf içeren hem de anlamlı olmayan değişkenler
kaldirilacak_degiskenler = [
    column for column in nadir_siniflar.keys()
    if chi_square_df.loc[column, "Significant"] == False
]

# Belirlenen değişkenlerin veri setinden kaldırılması
veri_temizlenmis =  veri_temizlenmis.drop(columns=kaldirilacak_degiskenler, errors="ignore")

print("Kaldırılan Kategorik Değişkenler:", kaldirilacak_degiskenler)
print("Yeni Veri Seti Boyutları:",  veri_temizlenmis.shape)

# Hedef ve bağımsız değişkenlerin ayrılması
y = veri_temizlenmis['Glycemic_control']
X = veri_temizlenmis.drop(columns=['Glycemic_control'])

print("Bağımsız değişkenlerin boyutu:", X.shape)
print("Hedef değişkenin boyutu:", y.shape)

# Kategorik ve sayısal değişkenlerin ayrıştırılması
kategorik = [sutun for sutun in veri_temizlenmis.columns if veri[sutun].nunique() <= 10]
sayisal = [sutun for sutun in veri_temizlenmis.columns if sutun not in kategorik_degiskenler]

print("Sayısal değişkenler:", list(sayisal))
print("Kategorik değişkenler:", list(kategorik))

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Sadece sayısal veriler
X_sayisal = X[sayisal]

# Veriyi standartlaştırma
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_sayisal)

# PCA uygulanması
pca = PCA(n_components=0.95)  # %95 varyans
X_pca = pca.fit_transform(X_scaled)

print("PCA sonrası bağımsız değişken boyutu:", X_pca.shape)

# Sonuçları bir DataFrame'e çevirme
from sklearn.model_selection import train_test_split

# Eğitim ve test verisine ayırma
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)

print("Eğitim seti boyutu:", X_train.shape)
print("Test seti boyutu:", X_test.shape)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, f1_score, precision_score, recall_score,
    cohen_kappa_score, roc_auc_score, roc_curve
)
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
import matplotlib.pyplot as plt

# Eğitim ve test verilerine ayırma
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)

# Modeller
modeller = {
    "Lojistik Regresyon": LogisticRegression(max_iter=500),
    "Karar Ağacı": DecisionTreeClassifier(max_depth=5),
    "Random Forest": RandomForestClassifier(n_estimators=50, max_depth=10),
    "SVM": SVC(probability=True, kernel="linear"),  # Linear kernel daha hızlıdır
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=50, max_depth=3)
}


# Model sonuçlarını saklamak için
sonuclar = []

# ROC eğrisi için grafik oluşturma
plt.figure(figsize=(12, 8))

# Her modeli değerlendirme
for isim, model in modeller.items():
    # Modeli eğitme
    print(f"{isim} modeli eğitiliyor...")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

    # Değerlendirme metrikleri
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    sensitivity = recall_score(y_test, y_pred)  # Sensitivity = Recall
    kappa = cohen_kappa_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None

    # Sonuçları saklama
    sonuclar.append({
        "Model": isim,
        "Accuracy": accuracy,
        "F1-Score": f1,
        "Precision": precision,
        "Sensitivity": sensitivity,
        "Kappa": kappa,
        "AUC": auc
    })

    # ROC eğrisi
    if y_pred_proba is not None:
        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
        plt.plot(fpr, tpr, label=f"{isim} (AUC = {auc:.2f})")

# ROC eğrisi grafiği
plt.plot([0, 1], [0, 1], 'k--', label="Random Guessing")
plt.title("ROC Eğrileri")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

# Sonuçları bir DataFrame'e çevirme
sonuclar_df = pd.DataFrame(sonuclar)

# Sonuçları yazdırma
print(sonuclar_df)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt



# Veriyi standartlaştırma
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# MLP Modeli
def create_mlp(input_shape):
    model = Sequential([
        Dense(128, activation='relu', input_shape=(input_shape,)),
        Dropout(0.3),
        Dense(64, activation='relu'),
        Dropout(0.3),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Modeli oluşturma ve eğitme
mlp_model = create_mlp(X_train.shape[1])
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history_mlp = mlp_model.fit(X_train, y_train, validation_data=(X_test, y_test),
                            epochs=50, batch_size=32, callbacks=[early_stop])

# Doğruluk ve kayıp grafikleri
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history_mlp.history['loss'], label='Eğitim Kaybı')
plt.plot(history_mlp.history['val_loss'], label='Doğrulama Kaybı')
plt.title('MLP - Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_mlp.history['accuracy'], label='Eğitim Doğruluğu')
plt.plot(history_mlp.history['val_accuracy'], label='Doğrulama Doğruluğu')
plt.title('MLP - Accuracy')
plt.legend()
plt.show()

!pip install pytorch-tabnet

from pytorch_tabnet.tab_model import TabNetClassifier
from sklearn.metrics import accuracy_score, classification_report

# TabNet Modeli
tabnet_model = TabNetClassifier()

# Modeli eğitme
tabnet_model.fit(
    X_train=X_train, y_train=y_train,
    eval_set=[(X_test, y_test)],
    patience=10, max_epochs=200,
    eval_metric=['accuracy']
)

# Tahmin ve metrikler
y_pred = tabnet_model.predict(X_test)
print("TabNet Doğruluk Skoru:", accuracy_score(y_test, y_pred))
print("TabNet Sınıflandırma Raporu:\n", classification_report(y_test, y_pred))

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Dropout, Multiply

# Dikkat mekanizması katmanı
def attention_layer(input_layer):
    attention_probs = Dense(input_layer.shape[1], activation='softmax')(input_layer)
    attention_output = Multiply()([input_layer, attention_probs])
    return attention_output

# Model oluşturma
def create_attention_model(input_shape):
    inputs = Input(shape=(input_shape,))

    # Dikkat mekanizması
    attention_output = attention_layer(inputs)

    # Sinir ağı katmanları
    x = Dense(128, activation='relu')(attention_output)
    x = Dropout(0.3)(x)
    x = Dense(64, activation='relu')(x)
    x = Dropout(0.3)(x)
    outputs = Dense(1, activation='sigmoid')(x)  # Binary classification

    model = Model(inputs, outputs)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Modeli eğitme
attention_model = create_attention_model(X_train.shape[1])
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history_attention = attention_model.fit(X_train, y_train, validation_data=(X_test, y_test),
                                        epochs=50, batch_size=32, callbacks=[early_stop])

# Loss ve Accuracy grafikleri
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history_attention.history['loss'], label='Eğitim Kaybı')
plt.plot(history_attention.history['val_loss'], label='Doğrulama Kaybı')
plt.title('Attention Model - Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history_attention.history['accuracy'], label='Eğitim Doğruluğu')
plt.plot(history_attention.history['val_accuracy'], label='Doğrulama Doğruluğu')
plt.title('Attention Model - Accuracy')
plt.legend()
plt.show()

from sklearn.metrics import accuracy_score, classification_report, roc_auc_score

# Performans ölçümleri
models = {
    "MLP": mlp_model,
    "TabNet": tabnet_model,
    "Attention Model": attention_model
}

results = {}
for model_name, model in models.items():
    # Sürekli tahminler
    y_pred = (model.predict(X_test) > 0.5).astype(int)

    # Performans metriklerini hesaplama
    results[model_name] = {
        "accuracy": accuracy_score(y_test, y_pred),
        "roc_auc": roc_auc_score(y_test, model.predict(X_test)),  # Sürekli tahminler burada kullanılabilir
        "classification_report": classification_report(y_test, y_pred, output_dict=True)
    }

# En iyi modeli seçme
best_model = max(results, key=lambda x: results[x]['roc_auc'])
print(f"En iyi model: {best_model}")

# Tüm modellerin sonuçlarını birleştirme
def tum_modelleri_degerlendir():
    #  ML modellerinin sonuçlarını alma
    ml_sonuclar = sonuclar_df.copy()

    # MLP sonuçlarını ekleme
    mlp_pred = mlp_model.predict(X_test)
    mlp_pred_binary = (mlp_pred > 0.5).astype(int)
    mlp_pred_proba = mlp_model.predict(X_test)

    mlp_metrics = {
        "Model": "MLP",
        "Accuracy": accuracy_score(y_test, mlp_pred_binary),
        "F1-Score": f1_score(y_test, mlp_pred_binary),
        "Precision": precision_score(y_test, mlp_pred_binary),
        "Sensitivity": recall_score(y_test, mlp_pred_binary),
        "Kappa": cohen_kappa_score(y_test, mlp_pred_binary),
        "AUC": roc_auc_score(y_test, mlp_pred_proba)
    }

    # TabNet sonuçlarını ekleme
    tabnet_pred = tabnet_model.predict(X_test)
    tabnet_pred_proba = tabnet_model.predict_proba(X_test)[:, 1]

    tabnet_metrics = {
        "Model": "TabNet",
        "Accuracy": accuracy_score(y_test, tabnet_pred),
        "F1-Score": f1_score(y_test, tabnet_pred),
        "Precision": precision_score(y_test, tabnet_pred),
        "Sensitivity": recall_score(y_test, tabnet_pred),
        "Kappa": cohen_kappa_score(y_test, tabnet_pred),
        "AUC": roc_auc_score(y_test, tabnet_pred_proba)
    }

    # Attention Model sonuçlarını ekleme
    attention_pred = attention_model.predict(X_test)
    attention_pred_binary = (attention_pred > 0.5).astype(int)

    attention_metrics = {
        "Model": "Attention Model",
        "Accuracy": accuracy_score(y_test, attention_pred_binary),
        "F1-Score": f1_score(y_test, attention_pred_binary),
        "Precision": precision_score(y_test, attention_pred_binary),
        "Sensitivity": recall_score(y_test, attention_pred_binary),
        "Kappa": cohen_kappa_score(y_test, attention_pred_binary),
        "AUC": roc_auc_score(y_test, attention_pred)
    }

    # Tüm sonuçları birleştirme
    ml_sonuclar = pd.concat([ml_sonuclar,
                            pd.DataFrame([mlp_metrics]),
                            pd.DataFrame([tabnet_metrics]),
                            pd.DataFrame([attention_metrics])],
                           ignore_index=True)

    return ml_sonuclar

# Tüm modellerin karşılaştırmalı sonuçlarını alma
tum_sonuclar = tum_modelleri_degerlendir()

# En iyi modeli bulma (F1-Score)
en_iyi_model = tum_sonuclar.loc[tum_sonuclar['F1-Score'].idxmax()]

print("\n=== TÜM MODELLERİN KARŞILAŞTIRMALI SONUÇLARI ===")
print(tum_sonuclar.round(4))


# Tüm modellerin ROC eğrilerini çizme
plt.figure(figsize=(12, 8))
for model_name in tum_sonuclar['Model']:
    if model_name in modeller:  # ML modelleri için
        y_pred_proba = modeller[model_name].predict_proba(X_test)[:, 1]
    elif model_name == "MLP":
        y_pred_proba = mlp_model.predict(X_test).ravel()
    elif model_name == "TabNet":
        y_pred_proba = tabnet_model.predict_proba(X_test)[:, 1]
    else:  # Attention Model için
        y_pred_proba = attention_model.predict(X_test).ravel()

    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    auc = roc_auc_score(y_test, y_pred_proba)
    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.3f})')

plt.plot([0, 1], [0, 1], 'k--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Eğrileri Karşılaştırması')
plt.legend()
plt.show()

# Tüm modellerin sonuçlarını karşılaştırma fonksiyonu
def modelleri_karsilastir():
    # Makine Öğrenmesi Modelleri Sonuçları
    ml_sonuclar = pd.DataFrame(sonuclar)
    ml_sonuclar['Model_Tipi'] = 'Makine Öğrenmesi'

    # MLP Model Sonuçları
    mlp_pred = mlp_model.predict(X_test)
    mlp_pred_binary = (mlp_pred > 0.5).astype(int)
    mlp_metrics = {
        'Model': 'MLP',
        'Model_Tipi': 'Derin Öğrenme',
        'Accuracy': accuracy_score(y_test, mlp_pred_binary),
        'F1-Score': f1_score(y_test, mlp_pred_binary),
        'Precision': precision_score(y_test, mlp_pred_binary),
        'Sensitivity': recall_score(y_test, mlp_pred_binary),
        'Kappa': cohen_kappa_score(y_test, mlp_pred_binary),
        'AUC': roc_auc_score(y_test, mlp_pred.ravel())
    }

    # TabNet Model Sonuçları
    tabnet_pred = tabnet_model.predict(X_test)
    tabnet_pred_proba = tabnet_model.predict_proba(X_test)
    tabnet_metrics = {
        'Model': 'TabNet',
        'Model_Tipi': 'Derin Öğrenme',
        'Accuracy': accuracy_score(y_test, tabnet_pred),
        'F1-Score': f1_score(y_test, tabnet_pred),
        'Precision': precision_score(y_test, tabnet_pred),
        'Sensitivity': recall_score(y_test, tabnet_pred),
        'Kappa': cohen_kappa_score(y_test, tabnet_pred),
        'AUC': roc_auc_score(y_test, tabnet_pred_proba[:, 1])
    }

    # Attention Model Sonuçları
    attention_pred = attention_model.predict(X_test)
    attention_pred_binary = (attention_pred > 0.5).astype(int)
    attention_metrics = {
        'Model': 'Attention Model',
        'Model_Tipi': 'Derin Öğrenme',
        'Accuracy': accuracy_score(y_test, attention_pred_binary),
        'F1-Score': f1_score(y_test, attention_pred_binary),
        'Precision': precision_score(y_test, attention_pred_binary),
        'Sensitivity': recall_score(y_test, attention_pred_binary),
        'Kappa': cohen_kappa_score(y_test, attention_pred_binary),
        'AUC': roc_auc_score(y_test, attention_pred.ravel())
    }

    # Tüm sonuçları birleştirme
    tum_sonuclar = pd.concat([
        ml_sonuclar,
        pd.DataFrame([mlp_metrics]),
        pd.DataFrame([tabnet_metrics]),
        pd.DataFrame([attention_metrics])
    ], ignore_index=True)

    return tum_sonuclar

# Sonuçları hesaplama
tum_sonuclar = modelleri_karsilastir()

# Sonuçları görüntüleme
print("\n=== MODEL KARŞILAŞTIRMA SONUÇLARI ===")
print("\nTüm Modellerin Performans Metrikleri:")
print(tum_sonuclar.round(4))

# Model tipine göre ortalama performans
print("\nModel Tiplerine Göre Ortalama Performans:")
print(tum_sonuclar.groupby('Model_Tipi')[['Accuracy', 'F1-Score', 'AUC']].mean().round(4))

# En iyi modeli bulma (F1-Score)
en_iyi_model = tum_sonuclar.loc[tum_sonuclar['F1-Score'].idxmax()]
print("\n=== EN İYİ MODEL ===")
print(f"Model: {en_iyi_model['Model']} ({en_iyi_model['Model_Tipi']})")
print(f"Accuracy: {en_iyi_model['Accuracy']:.4f}")
print(f"F1-Score: {en_iyi_model['F1-Score']:.4f}")
print(f"Precision: {en_iyi_model['Precision']:.4f}")
print(f"Sensitivity: {en_iyi_model['Sensitivity']:.4f}")
print(f"Kappa: {en_iyi_model['Kappa']:.4f}")
print(f"AUC: {en_iyi_model['AUC']:.4f}")

# ROC eğrilerini çizme
plt.figure(figsize=(12, 8))

# Makine Öğrenmesi modelleri için ROC eğrileri
for model_name, model in modeller.items():
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    auc = roc_auc_score(y_test, y_pred_proba)
    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {auc:.3f})')

# Derin öğrenme modelleri için ROC eğrileri
# MLP
mlp_pred = mlp_model.predict(X_test)
fpr, tpr, _ = roc_curve(y_test, mlp_pred)
auc = roc_auc_score(y_test, mlp_pred)
plt.plot(fpr, tpr, label=f'MLP (AUC = {auc:.3f})')

# TabNet
tabnet_pred_proba = tabnet_model.predict_proba(X_test)[:, 1]
fpr, tpr, _ = roc_curve(y_test, tabnet_pred_proba)
auc = roc_auc_score(y_test, tabnet_pred_proba)
plt.plot(fpr, tpr, label=f'TabNet (AUC = {auc:.3f})')

# Attention Model
attention_pred = attention_model.predict(X_test)
fpr, tpr, _ = roc_curve(y_test, attention_pred)
auc = roc_auc_score(y_test, attention_pred)
plt.plot(fpr, tpr, label=f'Attention Model (AUC = {auc:.3f})')

plt.plot([0, 1], [0, 1], 'k--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Tüm Modeller için ROC Eğrileri Karşılaştırması')
plt.legend()
plt.show()

# Öznitelik önem analizi için yardımcı fonksiyonlar
def ozellik_onem_analizi(X_scaled, X, y):
    print("\n=== ÖZELLİK ÖNEM ANALİZİ ===")

    # Random Forest ile özellik önem skorları
    rf_model = RandomForestClassifier(random_state=42)
    rf_model.fit(X_scaled, y)
    rf_onem = pd.DataFrame({
        'Özellik': X.columns,
        'Random Forest Önem Skoru': rf_model.feature_importances_
    }).sort_values('Random Forest Önem Skoru', ascending=False)

    # Lojistik Regresyon katsayıları (mutlak değer)
    lr_model = LogisticRegression(max_iter=1000)
    lr_model.fit(X_scaled, y)
    lr_onem = pd.DataFrame({
        'Özellik': X.columns,
        'Lojistik Regresyon Önem Skoru': np.abs(lr_model.coef_[0])
    }).sort_values('Lojistik Regresyon Önem Skoru', ascending=False)

    # Gradient Boosting ile özellik önem skorları
    gb_model = GradientBoostingClassifier(random_state=42)
    gb_model.fit(X_scaled, y)
    gb_onem = pd.DataFrame({
        'Özellik': X.columns,
        'Gradient Boosting Önem Skoru': gb_model.feature_importances_
    }).sort_values('Gradient Boosting Önem Skoru', ascending=False)

    # Tüm önem skorlarını birleştir
    onem_df = rf_onem.merge(lr_onem, on='Özellik')
    onem_df = onem_df.merge(gb_onem, on='Özellik')

    # Ortalama önem skorunu hesapla
    onem_df['Ortalama Önem'] = onem_df[['Random Forest Önem Skoru', 'Lojistik Regresyon Önem Skoru', 'Gradient Boosting Önem Skoru']].mean(axis=1)
    onem_df = onem_df.sort_values('Ortalama Önem', ascending=False)

    return onem_df

# Veriyi hazırla
X_sayisal = X.select_dtypes(include=['float64', 'int64'])
X_scaled = StandardScaler().fit_transform(X_sayisal)
X_scaled_df = pd.DataFrame(X_scaled, columns=X_sayisal.columns)

# Özellik önem analizini gerçekleştir
onem_df = ozellik_onem_analizi(X_scaled, X_sayisal, y)

print("\nÖzellik Önem Sıralaması:")
print(onem_df)

# En önemli özellikleri görselleştir
plt.figure(figsize=(12, 6))
plt.bar(onem_df['Özellik'][:10], onem_df['Ortalama Önem'][:10])
plt.xticks(rotation=45, ha='right')
plt.title('En Önemli 10 Özellik')
plt.tight_layout()
plt.show()

# En iyi modeli seçme ve kaydetme fonksiyonu
def en_iyi_modeli_sec(modeller_dict, X_test, y_test):
    print("\n=== EN İYİ MODEL SEÇİMİ ===")

    model_sonuclari = []

    # Her model için performans metriklerini hesapla
    for model_adi, model in modeller_dict.items():
        try:
            if hasattr(model, 'predict'):
                y_pred = model.predict(X_test)
                accuracy = accuracy_score(y_test, y_pred)
                f1 = f1_score(y_test, y_pred)

                # Her iki metriğin ortalamasını al
                ortalama_skor = (accuracy + f1) / 2

                model_sonuclari.append({
                    'model_adi': model_adi,
                    'model': model,
                    'accuracy': accuracy,
                    'f1_score': f1,
                    'ortalama_skor': ortalama_skor
                })

                print(f"\n{model_adi} Performansı:")
                print(f"Accuracy: {accuracy:.4f}")
                print(f"F1-Score: {f1:.4f}")
                print(f"Ortalama Skor: {ortalama_skor:.4f}")

        except Exception as e:
            print(f"{model_adi} için hata: {str(e)}")
            continue

    # En yüksek ortalama skora sahip modeli seç
    en_iyi_model_bilgisi = max(model_sonuclari, key=lambda x: x['ortalama_skor'])

    return en_iyi_model_bilgisi

# Tahmin yapma fonksiyonu
def tahmin_yap(model, ornek_veri, scaler=None):
    """
    Yeni örnekler için tahmin yapan fonksiyon
    """
    if scaler:
        ornek_veri = scaler.transform(ornek_veri)

    tahmin = model.predict(ornek_veri)

    if hasattr(model, 'predict_proba'):
        olasiliklar = model.predict_proba(ornek_veri)
        return tahmin, olasiliklar

    return tahmin, None

# Tüm modelleri bir sözlükte topla
tum_modeller = {
    "Lojistik Regresyon": LogisticRegression(max_iter=500),
    "Random Forest": RandomForestClassifier(random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "SVM": SVC(probability=True),
    "MLP": mlp_model,
    "TabNet": tabnet_model,
    "Attention Model": attention_model
}

# En iyi modeli seç
en_iyi_model_bilgisi = en_iyi_modeli_sec(tum_modeller, X_test, y_test)

# En iyi modeli kaydet
import joblib
model_dosyasi = 'en_iyi_model.joblib'
scaler_dosyasi = 'scaler.joblib'

joblib.dump(en_iyi_model_bilgisi['model'], model_dosyasi)
joblib.dump(scaler, scaler_dosyasi)

print(f"\nModel ve scaler kaydedildi: {model_dosyasi}, {scaler_dosyasi}")

# Örnek tahminler için test verisinden birkaç örnek alalım
ornek_sayisi = 5
ornek_veriler = X_test[:ornek_sayisi]
gercek_degerler = y_test[:ornek_sayisi]

# Modeli ve scaler'ı yükle
yuklenen_model = joblib.load(model_dosyasi)
yuklenen_scaler = joblib.load(scaler_dosyasi)

# Tahminler yap
tahminler, olasiliklar = tahmin_yap(yuklenen_model, ornek_veriler, yuklenen_scaler)

print("\n=== ÖRNEK TAHMİNLER ===")
for i, (tahmin, gercek) in enumerate(zip(tahminler, gercek_degerler)):
    print(f"\nÖrnek {i+1}:")
    print(f"Tahmin: {tahmin}")
    print(f"Gerçek Değer: {gercek}")
    if olasiliklar is not None:
        print(f"Tahmin Olasılıkları: {olasiliklar[i]}")

